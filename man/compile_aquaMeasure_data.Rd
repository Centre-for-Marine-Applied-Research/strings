% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compile_aquaMeasure_data.R
\name{compile_aquaMeasure_data}
\alias{compile_aquaMeasure_data}
\title{Compiles temperature, dissolved oxygen, and/or salinity data from
 aquaMeasure deployment}
\usage{
compile_aquaMeasure_data(
  path.aM,
  area.name,
  serial.table.aM,
  deployment.range,
  trim = TRUE,
  export.csv = FALSE
)
}
\arguments{
\item{path.aM}{File path to the aquaMeasure folder. There should only be one
file in the aquaMeasure folder. A warning will be printed to the console if
there is more than one file. The function can accept .csv or .xlsx files.}

\item{area.name}{Area where aquaMeasure was deployed.}

\item{serial.table.aM}{A table with the serial number of each aquaMeasure on the
string, in the form "aquaMeasure-xxxxxx" (first column; note the capital
"M") and its corresponding depth in the form "2m" (second column).}

\item{deployment.range}{The start and end dates of deployment from the
deployment log. Must be in format "2018-Nov-15 to 2020-Jan-24".}

\item{trim}{Logical value indicating whether to trim the data to the dates
specified in \code{deployment.range}. (Note: four hours are added to the
retrieval date to account for AST, e.g., in case the sensor was retrieved
after 20:00 AST, which is 00:00 UTC the next day.) Default is \code{trim =
TRUE}.}

\item{export.csv}{Logical value indicating whether to export the compiled data
as a .csv file. If \code{export.csv = TRUE}, the compiled data will not be
returned to the global environment. Default is \code{export.csv = FALSE}.}
}
\value{
Returns a dataframe or exports a spreadsheet with the data compiled
 from each of the aquaMeasure sensors. Columns alternate between datetime
 (UTC, in the format "Y-m-d H:M:S") and variable value (rounded to three
 decimal places). Metadata at the top of each column indicates the deployment
 range, the sensor serial number, and the variable and depth of the sensor.
 Each datetime column shows the timezone as extracted from the aquaMeasure.

 To include the metadata, all values were converted to class
 \code{character}. To manipulate the data, the values must be converted to
 the appropriate class (e.g., \code{POSIXct} for the datetimes and
 \code{numeric} for variable values). This can be done using the function
 \code{convert_to_tidydata()}.
}
\description{
This functions re-formats the data from an aquaMeasure deployment
 so it can be combined with the HOBO and Vemco temperature data.
}
\details{
Might be able to get rid of parsing error by deleting Text column. IF
 you do this, make another folder inside aquaMeaure named Raw Data and save
 the unaltered data there

 Can handle .csv or .xlsx files.

 All columns in .xlsx files will be imported as characters to ensure dates
 are parsed correctly.

 The first 7 columns in .csv files will be imported as characters. There
 still may be parsing errors because there are not entries in every column.

 Rows with \code{undefined} and \code{... (time not set)} values in the
 \code{Timestamp(UTC)} column are filtered out.

 Negative Dissolved Oxygen values are replaced with \code{NA}.
}
\seealso{
Other compile: 
\code{\link{compile_HOBO_data}()},
\code{\link{compile_all_data}()},
\code{\link{compile_vemco_data}()},
\code{\link{convert_to_tidydata}()}
}
\author{
Danielle Dempsey
}
\concept{compile}
